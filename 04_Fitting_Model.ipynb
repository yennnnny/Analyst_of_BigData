{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터산업진흥원 제공 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Users/yeenn/Desktop/STUDY/빅데이터분석기사/문제예시/X_train.csv', encoding = 'cp949')\n",
    "X_test = pd.read_csv('C:/Users/yeenn/Desktop/STUDY/빅데이터분석기사/문제예시/X_test.csv', encoding = 'cp949')\n",
    "y_train = pd.read_csv('C:/Users/yeenn/Desktop/STUDY/빅데이터분석기사/문제예시/y_train.csv', encoding = 'cp949')\n",
    "\n",
    "print('X_train shape : ',  X_train.shape)\n",
    "print('X_test shape : ',  X_test.shape)\n",
    "print('y_train shape : ',  y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "numberic = ['총구매액', '최대구매액', '환불금액', '내점일수', '내점당구매건수', '주말방문비율', '구매주기']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[numberic])\n",
    "\n",
    "X_train[numberic] = scaler.transform(X_train[numberic])\n",
    "X_test[numberic] = scaler.transform(X_test[numberic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "cat = X_train.select_dtypes(include = 'object').columns  # ['주구매상품', '주구매지점']\n",
    "\n",
    "X_train['group'] = ['train'] * (len(X_train))\n",
    "X_test['group'] = ['test'] * (len(X_test))\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "\n",
    "for i in range(len(cat)):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder = encoder.fit(X[cat[i]])\n",
    "    X[cat[i]] = encoder.transform(X[cat[i]])\n",
    "    \n",
    "X_train = X[X['group'] == 'train'].drop(columns = ['group'])\n",
    "X_test = X[X['group'] == 'test'].drop(columns = ['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 채우기\n",
    "X_train['환불금액'] = X_train['환불금액'].fillna(0.0)\n",
    "X_test['환불금액'] = X_test['환불금액'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 컬럼제거\n",
    "y_train = y_train.drop(columns = ['cust_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf =  RandomForestClassifier(random_state = 42)\n",
    "bc = BaggingClassifier(random_state = 42)\n",
    "gbc = GradientBoostingClassifier(random_state = 42)\n",
    "ac = AdaBoostClassifier(random_state = 42)\n",
    "\n",
    "lsvc = LinearSVC(random_state = 42)\n",
    "nsvc = NuSVC(random_state = 42)\n",
    "svc = SVC(random_state = 42)\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state = 42)\n",
    "etc = ExtraTreeClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf =  RandomForestClassifier(random_state = 42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "# acc = accuracy_score(y_train, rf_pred)\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 4회 기출문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/yeenn/Desktop/input/06_test1/train.csv')\n",
    "test = pd.read_csv('C:/Users/yeenn/Desktop/input/06_test1/test.csv')\n",
    "\n",
    "# train/test set 생성\n",
    "X_train = train.drop(columns = ['Segmentation', 'ID'])\n",
    "y_train = train[['Segmentation', 'ID']]\n",
    "y_train_id = y_train['ID']\n",
    "y_train = y_train['Segmentation']\n",
    "y_test_id = test.pop('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입 변경\n",
    "cat = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\n",
    "num = ['Age', 'Work_Experience', 'Family_Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 범주형 컬럼 Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for i in range(len(cat)):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder = encoder.fit(X_train[cat[i]])\n",
    "    X_train[cat[i]] = encoder.transform(X_train[cat[i]])\n",
    "    test[cat[i]] = encoder.transform(test[cat[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 컬럼 MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(X_train[num])\n",
    "\n",
    "X_train[num] = scaler.transform(X_train[num])\n",
    "test[num] = scaler.transform(test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fitting\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predict = rf.predict(test)\n",
    "\n",
    "# 결과값\n",
    "result = pd.DataFrame({'ID' :test_id, 'predict' : predict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 서비스 이탈예측 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#데이터 로드\n",
    "x_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/churnk/X_train.csv\")\n",
    "y_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/churnk/y_train.csv\")\n",
    "x_test= pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/churnk/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Gender', 'Geography']  # ['Surname', 'Geography', 'Gender'] \n",
    "num = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "x_train['Gender'] = x_train['Gender'].str.lower()\n",
    "x_test['Gender'] = x_test['Gender'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for i in range(len(cat)):\n",
    "    model = LabelEncoder()\n",
    "    model = model.fit(x_train[cat[i]])\n",
    "\n",
    "    x_train[cat[i]] = model.transform(x_train[cat[i]])\n",
    "    x_test[cat[i]] = model.transform(x_test[cat[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(x_train[num])\n",
    "\n",
    "x_train[num] = scaler.transform(x_train[num])\n",
    "x_test[num] = scaler.transform(x_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test set 분할\n",
    "X_tr = x_train.drop(columns = ['CustomerId', 'Surname'])\n",
    "test = x_test.drop(columns = ['CustomerId', 'Surname'])\n",
    "y_tr = y_train.drop(columns = ['CustomerId',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_list = [RandomForestClassifier(), LogisticRegression(), KNeighborsClassifier(), GradientBoostingClassifier(), XGBClassifier(), SVC()]\n",
    "\n",
    "for model in model_list:\n",
    "    score = cross_val_score(estimator=model, X=X_tr, y=y_tr, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "    print(f\"{str(model)}\", \"\\n\", f\"ScoreMean: {score.mean():.3f}, ScoreStd: {score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 최적화 및 model fitting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "params = {'learning_rate' : (0.1, 0.01, 0.5),\n",
    "          'n_estimators' : (100, 50, 200),\n",
    "          'subsample' : (1.0, 1.5, 3.0),\n",
    "          'min_samples_split' : (1,  3),\n",
    "          'max_depth' : (3, 7)}\n",
    "\n",
    "grid_cv = GridSearchCV(model, params, cv =2, n_jobs = -1)\n",
    "model_grid_cv = grid_cv.fit(X_tr, y_tr)\n",
    "predict = model_grid_cv.predict(test)  # 예측값\n",
    "predict_proba = model_grid_cv.predict_proba(test)[:, 1]  # 예측값에 포함에될 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 서비스 이탈예측 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#데이터 로드\n",
    "x_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/airline/x_train.csv\")\n",
    "y_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/airline/y_train.csv\")\n",
    "x_test= pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/airline/x_test.csv\")\n",
    "y_test= pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/airline/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.select_dtypes(include = 'object').columns\n",
    "cat = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
    "# x_train.select_dtypes(exclude = 'object').columns\n",
    "num = ['Age', 'Flight Distance', 'Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelencoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for i in range(len(cat)):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder = encoder.fit(x_train[cat[i]])\n",
    "    \n",
    "    x_train[cat[i]] = encoder.transform(x_train[cat[i]])\n",
    "    x_test[cat[i]] = encoder.transform(x_test[cat[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(x_train[num])\n",
    "\n",
    "x_train[num] = scaler.transform(x_train[num])\n",
    "x_test[num] = scaler.transform(x_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test set\n",
    "x_tr = x_train.drop(columns = ['ID'])\n",
    "test = x_test.drop(columns = ['ID'])\n",
    "y_tr = y_train.drop(columns = ['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# modelf\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lst =  [XGBClassifier(), XGBRFClassifier(), RandomForestClassifier(), AdaBoostClassifier(),\n",
    "          GradientBoostingClassifier(), DecisionTreeClassifier(), LinearRegression()]\n",
    "\n",
    "for model in model_lst:\n",
    "    score = cross_val_score(estimator = model, X = x_tr, y = y_tr, cv = 5, n_jobs = -1, scoring = 'roc_auc')\n",
    "    print('---------------')\n",
    "    print(str(model))\n",
    "    print('ScoreMean : ', str(score.mean()))\n",
    "    print('ScoreStd : ', str(score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 최적화\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model =  XGBRFClassifier()\n",
    "params = {\n",
    "    'learning_rate' : (1, 5, 10),\n",
    "    'subsample' : (0.1, 0.5, 0.8, 1.0),\n",
    "    'colsample_bynode' : (0.3,0.8),\n",
    "    'reg_lambda' : (1e-05, 1e-03)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model,params, cv = 2, n_jobs = -1)\n",
    "grid_model = grid.fit(x_tr, y_tr)\n",
    "predict = grid_model.predict(test)  # 예측값\n",
    "predict_proba = grid_model.predict_proba(test)[:, 1]  # 예측값에 포함에될 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'ID' : x_test['ID'], 'result' : predict_proba})\n",
    "result.to_csv('C:/Users/yeenn/Desktop/input/output/005002805.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 서비스 이탈예측 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/studentscore/X_train.csv\")\n",
    "y_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/studentscore/y_train.csv\")\n",
    "x_test= pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/studentscore/X_test.csv\")\n",
    "y_test= pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/studentscore/y_test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.select_dtypes(include = 'object').columns\n",
    "cat = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
    "       'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
    "       'nursery', 'higher', 'internet', 'romantic']\n",
    "\n",
    "x_train.select_dtypes(exclude = 'object').columns\n",
    "num = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime',\n",
    "       'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health',\n",
    "       'absences', 'G1', 'G2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for i in range(len(cat)):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder = encoder.fit(x_train[cat[i]])\n",
    "\n",
    "    x_train[cat[i]] = encoder.transform(x_train[cat[i]])\n",
    "    x_test[cat[i]] = encoder.transform(x_test[cat[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(x_train[num])\n",
    "\n",
    "x_train[num] = scaler.transform(x_train[num])\n",
    "x_test[num] = scaler.transform(x_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_train.drop(columns = ['StudentID'])\n",
    "test = x_test.drop(columns = ['StudentID'])\n",
    "y_tr = y_train.drop(columns = ['StudentID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "SVR()\n",
      "score_mean :  0.4818841173114379\n",
      "score_std :  0.055475845673437725\n",
      "----------\n",
      "DecisionTreeRegressor()\n",
      "score_mean :  0.7145367069994549\n",
      "score_std :  0.07638327330315951\n",
      "----------\n",
      "RandomForestRegressor()\n",
      "score_mean :  0.8450649560905015\n",
      "score_std :  0.030949924920442514\n",
      "----------\n",
      "ExtraTreesRegressor()\n",
      "score_mean :  0.8299262710850087\n",
      "score_std :  0.034230897246378865\n",
      "----------\n",
      "BaggingRegressor()\n",
      "score_mean :  0.8480734141376558\n",
      "score_std :  0.022260329977510773\n",
      "----------\n",
      "GradientBoostingRegressor()\n",
      "score_mean :  0.8614805369075864\n",
      "score_std :  0.03541814337179449\n",
      "----------\n",
      "AdaBoostRegressor()\n",
      "score_mean :  0.8288964146843594\n",
      "score_std :  0.011041832999132955\n",
      "----------\n",
      "LinearRegression()\n",
      "score_mean :  0.8357153989885846\n",
      "score_std :  0.039560005441710726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeenn\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "LogisticRegression()\n",
      "score_mean :  0.45190238449238196\n",
      "score_std :  0.05054502756475725\n",
      "----------\n",
      "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "             gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None)\n",
      "score_mean :  0.8293882970354917\n",
      "score_std :  0.038834909352638274\n",
      "----------\n",
      "XGBRFRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "               colsample_bytree=None, gamma=None, gpu_id=None,\n",
      "               importance_type='gain', interaction_constraints=None,\n",
      "               max_delta_step=None, max_depth=None, min_child_weight=None,\n",
      "               missing=nan, monotone_constraints=None, n_estimators=100,\n",
      "               n_jobs=None, num_parallel_tree=None,\n",
      "               objective='reg:squarederror', random_state=None, reg_alpha=None,\n",
      "               scale_pos_weight=None, tree_method=None,\n",
      "               validate_parameters=None, verbosity=None)\n",
      "score_mean :  0.8529808726656437\n",
      "score_std :  0.03433348576428216\n"
     ]
    }
   ],
   "source": [
    "# model select\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# model\n",
    "model_lst = [SVR(), DecisionTreeRegressor(), RandomForestRegressor(), ExtraTreesRegressor(), BaggingRegressor(),\n",
    "             GradientBoostingRegressor(), AdaBoostRegressor(), LinearRegression(), LogisticRegression(),\n",
    "             XGBRegressor(), XGBRFRegressor()]\n",
    "\n",
    "for model in model_lst:\n",
    "    cross_score = cross_val_score(model, X = x_tr, y = y_tr, cv = 5, n_jobs = -1, scoring  = 'r2')\n",
    "    print('----------')\n",
    "    print(str(model))\n",
    "    print('score_mean : ', cross_score.mean())\n",
    "    print('score_std : ', cross_score.std())\n",
    "    \n",
    "# GradientBoostingRegressor()\n",
    "# score_mean :  0.8614805369075864\n",
    "# score_std :  0.03541814337179449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeenn\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# parameter 최적화\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "param = {\n",
    "    'learning_rate' : (0.1, 0.5, 1.0),\n",
    "    'n_estimators' : (100, 500),\n",
    "    'subsample' : (1.0, 3.0, 5.0),\n",
    "    'min_samples_split' : (2, 3),\n",
    "    'max_depth' : (3, 5),\n",
    "    'alpha' : (0.3, 0.5, 0.9),  \n",
    "}\n",
    "\n",
    "grid_model = GridSearchCV(model, param, cv = 2, n_jobs = -1)\n",
    "grid_model = grid_model.fit(x_tr, y_tr)\n",
    "\n",
    "predict = grid_model.predict(test)\n",
    "# predict_proba = grid_model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ㅇ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
